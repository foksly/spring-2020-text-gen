# Постановка задачи
Напишите программу, которая генерирует тексты
на основе [N-граммной](https://en.wikipedia.org/wiki/N-gram) модели языка.

Основное задание можно разбить на следующие этапы:
1. Найти корпус текстов для обучения модели. 
Суммарное количество слов должно быть не меньше 20млн
2. Подготовить тексты для дальнейшей работы. Например, можно привести 
текст к нижнему регистру и удалить "лишнюю" пунктуацию (скобки, кавычки и т.д.)
3. Разбить тексты на предложения. В базовом варианте можно разбивать по символам *['.', '?', '!']*.
Можно рассмотреть и иные варианты: *томита-парсер* или модуль *nltk*
4. Разбить предложения на токены (слова), например по пробелу. 
Учтите, что запятые таким образом не отделятся от слова.
5. Посчитать статистику по биграмам в полученных предложениях. 
Не забудьте добавить вспомогательные токены начала и конца предложения.
6. Применить модель из предыдущего пункта для генерации текста из нескольких предложений. 
Предложения должны начинаться с заглавной буквы и оканчиваться знаком пунктуации 
(точка, восклицательный знак и т.п.). Для сэмплирования слов может потребоваться модуль *random*
7. Написать отчет, который должен описывать вашу реализацию.  

Каждый из вышеуказанных пунктов можно реализовать по разному, поэтому опишите какие решения вы приняли
в каждом из них (напр. какие тексты вы использовали). Приведите пример сгенерированного текста.

### Советы и указания:
* Сгенерируйте тексты с разными N. Заметна ли качественная разница?
* Попробуйте использовать посимвольные N-граммы
* Поддержите возможность сохранять модель в файл. Здесь вам помогут модули *json* или *pickle*
* (опционально) Реализуйте генерацию текста с помощью *сглаженной* (ngram smoothing) модели
* (опционально) Реализуйте command-line interface (CLI), например, с помощью модуля `argparse` или `click`.

----
## Требования:
1. Реализуйте методы класса `TextGenerator` в `text_generator.py`
    - `prepare_data` должен предобрабатывать "сырые" тексты для построения модели. К примеру, предобработка может включать в себя приведение всех слов к нижнему регистру, токенизацию, добавление специальных токенов и т.д. Параметры:
        - `data_path` - путь к вашему набору текстовых данных.
    - `build_model` должен выполнять построение N-граммной модели и иметь возможность сохранять построенную модель. Параметры: 
        - `data` - предобработанные данные, которые возвращает метод `prepare_data`
        - `ngram_size` - размер n-грамм в модели
        - `save_path` - путь для сохранения модели
    - `generate` должен генерировать текст на основе построенной модели. Параметры:
        - `length` - длина сгенерированного текста
        - `model` - построенная модель
        - `saved_model_path` - путь к файлу модели
2. Реализуйте функции `save_model` и `load_model` в файле `load_save.py`.  Здесь вам помогут модули `json` или `pickle`.
3. Код должен соответсвовать стилю из [PEP-8](https://www.python.org/dev/peps/pep-0008/) (допускается использование строчек длиной до 120 символов)
4. Напишите отчет в формате [Markdown](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet) в файле `report.md`. 
    - Опишите выбранные данные, а так же приведите статистики: из какой области данные, суммарное количество слов и количество уникальных слов.
    - Опишите метод предобработки данных.
    - Опишите результаты и приведите примеры. В примерах должно быть не менее 200 слов сгенерированного текста.

Указанные выше требования являются лишь минимальными требованиями для сдачи домашнего задания. Вы не ограничены в добавлении новых функций/классов/модулей/..., но в таком случае, необходимо, либо добавить комментарии в коде (согласно PEP8), либо добавить описания в отчет.

----
# Как сдавать задачу
Выполнить `python3 ../submit.py` как обычно.
Он отправит в систему все файлы в папке с расширениями py, md.
Папки использовать можно, но не более одного уровня вложенности!
Проверить что именно отправилось на проверку можно в своём приватном репозитори в ветке с задачей, 
ссылка на него есть на главной странице проверяющей системы в шапке.

Задачу надо сдать в систему до дедлайна, система выдаст 1 балл и проверит лишь что вы в срок сдали задание.
Проверка будет проходить в ручном режиме. Баллы проставят в табличку с оценками после проверки всех работ.

# Критерии оценки
Максимальный балл за задание - 200 баллов.
Сверх этого за задачу возможны бонусы. Бонусы - это баллы, которые идут в числитель накопительной оценки за курс, но не в знаменатель.

Выполнение минимальных требований и прохождение единственного теста - 100 баллов. За провал теста или невыполнение минимальных требований за задание будет выставлена оценка 0.


## Что влияет на оценку
Качество выходного текста. ~70 баллов из общей оценки

Постарайтесь добиться максимально возможного качества текста.

Начинает ли ваш генератор предложения с большой буквы? 
Что может оканчивать предложение?
Есть ли разбиение на абзацы?
Насколько вообще похоже на речь?

Качество отчёта. ~50 
Эту часть сложно формализовать, оценивается фантазия, находчивость, понимание матмодели происходящего, 
настойчивость в достижении цели и самореклама, конечно.

Обязательно опишите реализацию генератора и структуры данных, которые вы использовали.

Опишите также по возможности необходимое окружение для работы ваших скриптов (версия питона и необходимых библиотек).

Реализация.
Эффективные структуры данных. ~50
Хороший стиль кода (аккуратность, модульность, честные понятные имена, PEP8) - ~30 баллов.



Бонусы: за опциональные части задания, и например, за тесты. 
До 50 баллов, хотя зависит от того насколько вы нас удивите. Определённо, 
очень сложно поддержать честные падежи русского языка. Или прямую речь/диалоги.


## Материалы
1. [Speech and Language Processing. Daniel Jurafsky & James H. Martin](https://web.stanford.edu/~jurafsky/slp3/3.pdf)
2. Б.У. Керниган, Р. Пайк , 2017. Практика программирования. Третья глава.
